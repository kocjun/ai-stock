"""
ì‹œì¥ ë‰´ìŠ¤ ë¶„ì„ ë° ìš”ì•½ Crew

Google News RSS/NewsAPI(ì˜µì…˜)ì—ì„œ ì‹¤ì‹œê°„ ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì™€
ì‹œì¥ ì§€í‘œÂ·KOSPI ETF ë¶„ì„ê³¼ í•¨ê»˜ ì´ë©”ì¼ìš© ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•œë‹¤.
"""

from __future__ import annotations

import hashlib
import json
import os
import sys
from datetime import datetime
from pathlib import Path
from textwrap import shorten
from typing import Any, Dict, List, Tuple

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# .env íŒŒì¼ ë¡œë“œ (ì„ íƒì‚¬í•­, í™˜ê²½ ë³€ìˆ˜ë¡œ override ê°€ëŠ¥)
try:
    from dotenv import load_dotenv

    env_file = project_root / ".env"
    if env_file.exists():
        load_dotenv(env_file)
except ImportError:
    pass

try:
    from core.agents.kospi_etf_analyzer import analyze_kospi
except Exception:  # pragma: no cover - ë¶„ì„ ëª¨ë“ˆì´ ë¹„í™œì„±í™”ëœ ê²½ìš° ëŒ€ë¹„
    analyze_kospi = None

from core.utils.market_metrics import format_snapshot_lines, get_market_snapshot
from core.utils.news_fetcher import MarketNewsFetcher

SECTION_CONFIG: List[Tuple[str, str]] = [
    ("global", "ğŸŒ ê¸€ë¡œë²Œ ì‹œì¥"),
    ("semiconductor", "ğŸ”§ ë°˜ë„ì²´ ì„¹í„°"),
    ("geopolitical", "âš”ï¸ ì§€ì •í•™ ë¦¬ìŠ¤í¬"),
    ("korea", "ğŸ‡°ğŸ‡· êµ­ë‚´ ì‹œì¥"),
]

HISTORY_DIR = project_root / "reports" / "market_news_history"
HISTORY_FILE = HISTORY_DIR / "history.json"


def _mock_article(title: str, source: str, description: str, impact: str, category: str) -> Dict[str, Any]:
    return {
        "title": title,
        "source": source,
        "impact": impact,
        "category": category,
        "description": description,
        "summary": description,
        "link": "",
        "published_at": None,
    }


def get_mock_global_news_data() -> List[Dict]:
    """RSS/API ì‹¤íŒ¨ ì‹œ ì‚¬ìš©í•  ê¸°ë³¸ ê¸€ë¡œë²Œ ë‰´ìŠ¤"""
    return [
        _mock_article(
            "Fed ê¸ˆë¦¬ ì¸ìƒ ì˜ˆê³ ",
            "Reuters",
            "ì—°ì¤€ì´ ì¶”ê°€ ê¸ˆë¦¬ ì¸ìƒì„ ì‹œì‚¬í•˜ë©° ë‹¬ëŸ¬ ê°•ì„¸ ìš°ë ¤ê°€ ì»¤ì§‘ë‹ˆë‹¤.",
            "high",
            "global",
        ),
        _mock_article(
            "S&P500 ì‹ ê³ ê°€ ê²½ì‹ ",
            "Bloomberg",
            "ë¯¸êµ­ ì¦ì‹œëŠ” ê¸°ìˆ ì£¼ ê°•ì„¸ ë•ì— ì‚¬ìƒ ìµœê³ ì¹˜ë¥¼ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤.",
            "medium",
            "global",
        ),
        _mock_article(
            "Tesla ë°°í„°ë¦¬ ê¸°ìˆ  í˜ì‹ ",
            "TechCrunch",
            "í…ŒìŠ¬ë¼ê°€ ì°¨ì„¸ëŒ€ ë°°í„°ë¦¬ë¥¼ ê³µê°œí•˜ë©° ì „ê¸°ì°¨ ì‚°ì—… ì¬í¸ ê°€ëŠ¥ì„±ì„ ì•Œë ¸ìŠµë‹ˆë‹¤.",
            "medium",
            "global",
        ),
    ]


def get_mock_semiconductor_news_data() -> List[Dict]:
    return [
        _mock_article(
            "Samsung 3nm ê³µì • ì–‘ì‚° ëŒì…",
            "ì „ìì‹ ë¬¸",
            "ì‚¼ì„±ì „ìê°€ ì°¨ì„¸ëŒ€ 3nm ê³µì •ì— ì„±ê³µí•˜ë©° íŒŒìš´ë“œë¦¬ ê²½ìŸë ¥ì„ ê°•í™”í–ˆìŠµë‹ˆë‹¤.",
            "high",
            "semiconductor",
        ),
        _mock_article(
            "TSMC íŒŒìš´ë“œë¦¬ ìˆ˜ì£¼ ì¦ê°€",
            "DigiTimes",
            "TSMC ìˆ˜ì£¼ì”ê³ ê°€ ëŠ˜ì–´ë‚˜ë©° ê³µê¸‰ ë¶€ì¡±ì´ ì‹¬í™”ë˜ê³  ìˆìŠµë‹ˆë‹¤.",
            "high",
            "semiconductor",
        ),
        _mock_article(
            "SK Hynix ë©”ëª¨ë¦¬ ê°€ê²© íšŒë³µ",
            "ë‰´ìŠ¤1",
            "DDR5 ê°€ê²© íšŒë³µìœ¼ë¡œ SK Hynix ì‹¤ì  ê°œì„  ê¸°ëŒ€ê°€ í™•ëŒ€ë©ë‹ˆë‹¤.",
            "medium",
            "semiconductor",
        ),
    ]


def get_mock_geopolitical_news_data() -> List[Dict]:
    return [
        _mock_article(
            "ë¯¸ì¤‘ ê¸°ìˆ  ê°ˆë“± ì‹¬í™”",
            "BBC",
            "ë¯¸êµ­ì˜ ì¶”ê°€ ì œì¬ ì˜ˆê³ ë¡œ ë°˜ë„ì²´ ê³µê¸‰ë§ ë¶ˆí™•ì‹¤ì„±ì´ ì¦í­ë©ë‹ˆë‹¤.",
            "high",
            "geopolitical",
        ),
        _mock_article(
            "í•œë°˜ë„ ê¸´ì¥ ê³ ì¡°",
            "ì—°í•©ë‰´ìŠ¤",
            "ë¶í•œ ë¯¸ì‚¬ì¼ ë°œì‚¬ ì´í›„ ë°©ìœ„ì‚°ì—…ì£¼ì˜ ìˆ˜ê¸‰ì´ ì‚´ì•„ë‚˜ê³  ìˆìŠµë‹ˆë‹¤.",
            "high",
            "geopolitical",
        ),
        _mock_article(
            "ëŸ¬-ìš° ì „ìŸ ì¥ê¸°í™”",
            "Reuters",
            "ì—ë„ˆì§€ ê°€ê²© ë³€ë™ì„±ì´ í™•ëŒ€ë˜ë©° ê¸€ë¡œë²Œ ìˆ˜ìš” ë‘”í™” ìš°ë ¤ê°€ ì´ì–´ì§‘ë‹ˆë‹¤.",
            "medium",
            "geopolitical",
        ),
    ]


def get_mock_korea_news_data() -> List[Dict]:
    return [
        _mock_article(
            "í•œì€ ê¸ˆë¦¬ ê²°ì • ì„ë°•",
            "ì—°í•©ë‰´ìŠ¤",
            "í•œêµ­ì€í–‰ ê¸ˆí†µìœ„ê°€ ë§¤íŒŒ ê¸°ì¡°ë¥¼ ìœ ì§€í•  ê²ƒìœ¼ë¡œ ì „ë§ë©ë‹ˆë‹¤.",
            "high",
            "korea",
        ),
        _mock_article(
            "ì›/ë‹¬ëŸ¬ í™˜ìœ¨ ìƒìŠ¹",
            "ë§¤ì¼ê²½ì œ",
            "ì›í™” ì•½ì„¸ê°€ ì‹¬í™”ë˜ë©° ìˆ˜ì¶œì£¼ì—ëŠ” ìš°í˜¸ì ì¸ í™˜ê²½ì´ ì¡°ì„±ë©ë‹ˆë‹¤.",
            "high",
            "korea",
        ),
        _mock_article(
            "ì½”ìŠ¤í”¼ 200 ì„ ë¬¼ ë³€ë™ì„± í™•ëŒ€",
            "ë§ˆì¼“ë‰´ìŠ¤",
            "ì•¼ê°„ì„ ë¬¼ ë³€ë™ì„±ìœ¼ë¡œ ê°œì¥ ì§í›„ ë°©í–¥ì„±ì´ ë‹¤ì†Œ í”ë“¤ë¦´ ì „ë§ì…ë‹ˆë‹¤.",
            "medium",
            "korea",
        ),
    ]


def fetch_news_with_fallback() -> Dict[str, List[Dict]]:
    """ì‹¤ì‹œê°„ ë‰´ìŠ¤ ìˆ˜ì§‘ + ëª¨ì˜ ë°ì´í„° í´ë°±"""
    fetcher = MarketNewsFetcher(logger=lambda msg: print(msg))
    fetched = fetcher.fetch_all()

    return {
        "global": fetched.get("global") or get_mock_global_news_data(),
        "semiconductor": fetched.get("semiconductor") or get_mock_semiconductor_news_data(),
        "geopolitical": fetched.get("geopolitical") or get_mock_geopolitical_news_data(),
        "korea": fetched.get("korea") or get_mock_korea_news_data(),
    }


def render_section(title: str, articles: List[Dict]) -> str:
    lines = [f"## {title}"]
    if not articles:
        lines.append("- ê´€ë ¨ ê¸°ì‚¬ê°€ ë¶€ì¡±í•´ ê¸°ë³¸ ë°ì´í„°ë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.")
        return "\n".join(lines)

    for article in articles[:5]:
        source = article.get("source") or "ì¶œì²˜ ë¯¸ìƒ"
        impact = (article.get("impact") or "medium").upper()
        published = format_article_time(article.get("published_at"))
        headline = f"- **{article.get('title')}** ({source}"
        if published:
            headline += f", {published}"
        headline += f") [Impact: {impact}]"
        lines.append(headline)

        summary = article.get("summary") or article.get("description") or ""
        summary = shorten(summary.replace("\n", " "), width=160, placeholder="â€¦") if summary else ""
        if summary:
            lines.append(f"  - {summary}")

        link = article.get("link")
        if link:
            lines.append(f"  - ë§í¬: {link}")
    lines.append("")
    return "\n".join(lines)


def format_article_time(value: Any) -> str:
    if not value:
        return ""
    try:
        dt = datetime.fromisoformat(str(value).replace("Z", "+00:00"))
    except ValueError:
        return ""
    local = dt.astimezone()
    return local.strftime("%m-%d %H:%M")


def build_insights(news_sections: Dict[str, List[Dict]]) -> str:
    total_articles = sum(len(items) for items in news_sections.values())
    high_impact = sum(
        1
        for items in news_sections.values()
        for article in items
        if str(article.get("impact", "")).lower() == "high"
    )
    category_breakdown = ", ".join(
        f"{title}: {len(news_sections.get(key, []))}ê±´"
        for key, title in SECTION_CONFIG
    )

    return "\n".join(
        [
            "## ğŸ§­ ì¢…í•© ì¸ì‚¬ì´íŠ¸",
            f"- ì „ì²´ ê¸°ì‚¬ {total_articles}ê±´ ì¤‘ ê³ ìœ„í—˜ ì´ìŠˆ {high_impact}ê±´ íƒì§€",
            f"- ì¹´í…Œê³ ë¦¬ ë¶„í¬: {category_breakdown}",
            "- ë°˜ë³µ ìˆ˜ì‹  ì—¬ë¶€: ì €ì¥ëœ íˆìŠ¤í† ë¦¬ë¡œ ì¤‘ë³µ ê°ì§€",
            "",
        ]
    )


def flatten_news_items(news_sections: Dict[str, List[Dict]]) -> List[Dict]:
    items = []
    for key, articles in news_sections.items():
        for article in articles:
            data = dict(article)
            data["section"] = key
            items.append(data)
    return items


def record_report_history(report: str, news_items: List[Dict], snapshot: Dict) -> bool:
    HISTORY_DIR.mkdir(parents=True, exist_ok=True)
    history: List[Dict] = []
    if HISTORY_FILE.exists():
        try:
            history = json.loads(HISTORY_FILE.read_text(encoding="utf-8"))
        except json.JSONDecodeError:
            history = []

    entry = {
        "timestamp": datetime.now().isoformat(),
        "hash": hashlib.sha256(report.encode("utf-8")).hexdigest(),
        "article_count": len(news_items),
        "snapshot": snapshot,
    }

    duplicate = bool(history and history[-1].get("hash") == entry["hash"])
    entry["duplicate_with_previous"] = duplicate
    history.append(entry)
    history = history[-60:]  # ìµœê·¼ 60ê±´ë§Œ ìœ ì§€

    HISTORY_FILE.write_text(json.dumps(history, ensure_ascii=False, indent=2), encoding="utf-8")
    return duplicate


def build_report(news_sections: Dict[str, List[Dict]], snapshot: Dict, kospi_report: str | None) -> str:
    now_str = datetime.now().strftime("%Yë…„ %mì›” %dì¼ %H:%M")
    lines = [
        "## ğŸ“Š ì˜¤ëŠ˜ì˜ ì‹œì¥ ë‰´ìŠ¤ ìš”ì•½",
        f"**ìƒì„± ì‹œê°**: {now_str}",
        "**ë°ì´í„° ì†ŒìŠ¤**: Google News RSS + FinanceDataReader ì§€í‘œ ìŠ¤ëƒ…ìƒ·",
        "",
        format_snapshot_lines(snapshot),
    ]

    for key, title in SECTION_CONFIG:
        lines.append(render_section(title, news_sections.get(key, [])))

    lines.append(build_insights(news_sections))

    if kospi_report:
        lines.append("## ğŸ“Œ KOSPI ì§€ìˆ˜ & ETF ì¸ì‚¬ì´íŠ¸")
        lines.append(kospi_report)

    lines.append(
        "\nâš–ï¸ ë³¸ ë¦¬í¬íŠ¸ëŠ” ì •ë³´ ì œê³µìš©ì´ë©° íˆ¬ì ì¡°ì–¸ì´ ì•„ë‹™ë‹ˆë‹¤. "
        "ê²°ì • ì „ ê°œì¸ì˜ ë¦¬ìŠ¤í¬ í—ˆìš© ë²”ìœ„ë¥¼ ê²€í† í•˜ì„¸ìš”."
    )

    return "\n".join(line for line in lines if line).strip()


def generate_market_news_report() -> Dict[str, Any]:
    """
    ì‹œì¥ ë‰´ìŠ¤ ë¦¬í¬íŠ¸ + ì½”ìŠ¤í”¼ ì§€ìˆ˜ ETF ë¶„ì„ ìƒì„±
    """
    try:
        print("=" * 60)
        print("ğŸ“° ì‹œì¥ ë‰´ìŠ¤ ë¶„ì„ ì‹œì‘...")
        print("=" * 60)

        news_sections = fetch_news_with_fallback()
        snapshot = get_market_snapshot()

        kospi_meta = None
        kospi_report = None
        if analyze_kospi:
            try:
                kospi_meta, kospi_report = analyze_kospi(news_sections)
            except Exception as exc:
                print(f"âš ï¸  KOSPI ë¶„ì„ ì‹¤íŒ¨: {exc}")

        report = build_report(news_sections, snapshot, kospi_report)
        flattened = flatten_news_items(news_sections)
        duplicate = record_report_history(report, flattened, snapshot)

        return {
            "success": True,
            "timestamp": datetime.now().isoformat(),
            "report": report,
            "news_items": flattened,
            "snapshot": snapshot,
            "kospi_analysis": kospi_meta,
            "duplicate_with_previous": duplicate,
            "category": "comprehensive_market_analysis",
        }

    except Exception as exc:
        print(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {exc}")
        return {"success": False, "error": str(exc)}


if __name__ == "__main__":
    result = generate_market_news_report()

    if result["success"]:
        print("\n" + "=" * 60)
        print("ğŸ“‹ ìµœì¢… ì¢…í•© ì‹œì¥ ë¶„ì„ ë¦¬í¬íŠ¸")
        print("=" * 60)
        print()
        print(result["report"])
        print()
        print("=" * 60)
        print("âœ… ë¶„ì„ ì™„ë£Œ!")
        if result.get("duplicate_with_previous"):
            print("âš ï¸  ì´ì „ ê²°ê³¼ì™€ ë™ì¼í•œ ë¦¬í¬íŠ¸ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")

        print("\n" + "=" * 60)
        print("ğŸ“§ ì´ë©”ì¼ ë°œì†¡")
        print("=" * 60)

        try:
            from core.utils.market_news_sender import send_market_news_email

            success = send_market_news_email(
                result["report"],
                use_smtp=True,
                news_items=result.get("news_items"),
            )

            if success:
                print("\nâœ… ì´ë©”ì¼ ë°œì†¡ ì™„ë£Œ!")
            else:
                print("\nâš ï¸  ì´ë©”ì¼ ë°œì†¡ ì‹¤íŒ¨ (ë¶„ì„ì€ ì™„ë£Œë¨)")

        except Exception as exc:
            print(f"\nâš ï¸  ì´ë©”ì¼ ë°œì†¡ ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {exc}")
            print("   ë¶„ì„ ê²°ê³¼ëŠ” ì •ìƒì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

    else:
        print(f"\nâŒ ì˜¤ë¥˜: {result['error']}")
        sys.exit(1)
